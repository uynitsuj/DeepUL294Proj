{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandeepmukh/DeepUL294Proj/.deepulenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from mae.models_mae import MaskedAutoencoderViT, partial\n",
    "sys.path.append('../..')\n",
    "from DUL294P.encoders.openclip_encoder import *\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipencoder = OpenCLIPNetworkConfig(device='cpu').setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['pool_proj.weight', 'pool_proj.bias'], unexpected_keys=[])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 196, 768]), torch.Size([1, 512]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MaskedAutoencoderViT(\n",
    "        patch_size=16, embed_dim=768, depth=12, num_heads=12,\n",
    "        decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16,\n",
    "        mlp_ratio=4, out_chans=768, norm_layer=partial(nn.LayerNorm, eps=1e-6), return_pooled=True)\n",
    "sd=torch.load('../models/mae_pretrain_vit_base_full.pth')['model']\n",
    "msg = model.load_state_dict(sd, strict=False)\n",
    "print(msg)\n",
    "\n",
    "img = torch.randn(1, 3, 224, 224)\n",
    "target = model.patchify(img)\n",
    "latent, mask, ids_restore = model.forward_encoder(img, .75)\n",
    "pred, pooled = model.forward_decoder(latent, ids_restore)\n",
    "pred.shape, pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipencoder.model.encode_text(clipencoder.tokenizer(['a photo of a cat', 'nofdnjk']), normalize=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipencoder.process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[35.9688, 26.9219, 27.5469, 26.9531, 26.4844, 27.8750, 28.6562, 27.5312,\n",
       "         27.2344, 28.4688, 27.3594, 27.8594, 41.1562, 28.4688, 28.2188, 26.7344,\n",
       "         29.3594, 28.0469, 39.6250, 40.3438, 31.9531, 28.2031, 26.8750, 27.2031,\n",
       "         26.1875, 28.1094, 27.6562, 28.1719, 29.8750, 27.7500, 26.7812, 28.7812,\n",
       "         28.3750, 26.7344, 28.2656, 26.8438, 28.1094, 26.6562, 28.5469, 27.5000,\n",
       "         27.6875, 27.7344, 28.1094, 28.9219, 26.4531, 27.4531, 27.0625, 43.6562,\n",
       "         28.2969, 27.8906, 27.5312, 28.8281, 29.6406, 28.6250, 27.5938, 29.4844,\n",
       "         29.3750, 29.1406, 28.2500, 28.6562, 29.4844, 28.4531, 28.8750, 28.0000,\n",
       "         27.4844, 28.0625, 27.1719, 27.9219, 28.0469, 28.6562, 28.0156, 29.8750,\n",
       "         27.0156, 29.0000, 28.9531, 27.4375, 28.0000, 28.1562, 28.6562, 27.8281,\n",
       "         28.0625, 28.1094, 28.8281, 26.1094, 28.3281, 26.4531, 28.5625, 26.9844,\n",
       "         29.8281, 28.6406, 27.3750, 27.3594, 27.9062, 27.8125, 26.9219, 29.8750,\n",
       "         27.1094, 27.7188, 27.2969, 28.9844, 27.5312, 28.9062, 27.6406, 27.1719,\n",
       "         29.2812, 34.6250, 29.4219, 39.5625, 27.6719, 28.7656, 26.9219, 27.6719,\n",
       "         27.7344, 28.8281, 28.5312, 28.5938, 27.9844, 29.0312, 27.4062, 29.3125,\n",
       "         27.0312, 28.1250, 29.0781, 28.3594, 28.0156, 29.0625, 27.1250, 26.4844,\n",
       "         34.1562, 28.8906, 27.3750, 27.7969, 29.0469, 30.2188, 28.4219, 28.5625,\n",
       "         31.5938, 40.6562, 27.6250, 29.2031, 29.3438, 28.4375, 28.8750, 34.8750,\n",
       "         34.5000, 29.7969, 27.8750, 28.0156, 28.8125, 27.6094, 27.5938, 26.2031,\n",
       "         27.7812, 27.9688, 27.8438, 28.1250, 27.5625, 28.0156, 27.7031, 36.8438,\n",
       "         28.2344, 29.3438, 26.1719, 29.0000, 29.3438, 30.3281, 27.8438, 28.9062,\n",
       "         27.8594, 28.4688, 26.9062, 28.2188, 26.4219, 28.2812, 28.7812, 28.3594,\n",
       "         27.3750, 28.8125, 27.9531, 28.6719, 28.4219, 28.6875, 41.2188, 28.3438,\n",
       "         27.9375, 29.9531, 29.7500, 28.5625, 28.5312, 28.2031, 27.4219, 28.0938,\n",
       "         27.3438, 27.1875, 28.7969, 28.9219]], dtype=torch.float16,\n",
       "       grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pred.norm(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 196, 768]), torch.Size([1, 512]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_prepro = clipencoder.process(img).half()\n",
    "pooled, pred = clipencoder.model.encode_image(img_prepro)\n",
    "pred.shape, pooled.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".deepulenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
